---
title: "Simple Regression"
tutorial:
  id: "13-Simple-Regression"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: >
  Learn how to apply the lm function.
---

## Learning Objectives

In this tutorial, you will learn how to conduct simple regression analysis in R. Specifically we will cover:

* How to use the `lm()` function to estimate a regression
* How to use the `summary()` function to present the results of regression analysis
* How to use the regression output to test hypotheses about the intercept and slope using the five-step hypothesis testing procedure
* How to use the regression output to assess model fit



```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(knitr)
library(poliscidata)
library(gradethis)
tutorial_options(exercise.checker = gradethis::grade_learnr)
#tutorial_options(exercise.timelimit = 60)
knitr::opts_chunk$set(error = TRUE)
counties <- qpaTutorials::counties
counties$dem2p_percent <- counties$dem2p_vote_share*100
counties$wage_growth <- counties$wage_growth*100
counties$black_percent <- counties$prop_black*100
counties$White[counties$prop_white>0.5] <- 1
counties$White[counties$prop_white<=0.5] <- 0
df <- qpaTutorials::df
df$region <- factor(df$region, labels =  c("South", "Northeast", "Midwest", "West"))
library(poliscidata)
library(stargazer)
```

## Overview

<span style="color:blue">**Regression**</span> is a tool for estimating the linear relationship between one or more independent variables measured at any level and an outcome variable measured at the interval level. We use regression to test hypotheses about the effect of independent variables on the outcome. 


The `lm()` function in base R will estimate a linear regression model. We will illustrate how to use the `lm()` function to estimate a model, how to use the `summary()` function to produce a summary of the output, and we will practice interpreting results using several examples.


## Example 1: Vote for Hillary Clinton and Wage Growth

Let's say that we have posed the following question: Did wage growth in a county affect the share of the vote won by Hillary Clinton? We might make the argument that higher wage growth would lead voters to support the incumbent party candidate, Hillary Clinton, as voters would reward the Democratic president for improvements in their financial situation. By the same token, we might expect that lower wage growth (or declining wages) might lead them to support the challenger, Donald Trump. Thus we hypothesize:

 <span style="color:Chocolate">In a comparison of counties, those with higher wage growth will cast a higher percentage of the two-party vote share for Hillary Clinton than those counties with lower wage growth.</span>

The **counties** data frame contains the variables **wage_growth**, which is the percent by which wages grew or fell in a county, and **dem2p_percent**, which is the percent of the two-party vote in the county that was cast for Hillary Clinton. To test our hypothesis, we will estimate a linear regression in which **dem2p_percent** is the dependent variable and **wage_growth** is the independent variable.

### Estimate a Regression 

 Running a regression in R is really quite simple! The function to run a regression is `lm()`. This stands for "linear model." The function requires two arguments: a `formula` and `data`. 

What is a `formula`? R's `formula` specifies a relationship. It begins with the dependent variable and is followed by the tilde (~). The tilde in layman's terms can be read as "depends on." The formula ends with the explanatory variable (or variables, more in the next tutorial). So we specify `y~x`, where `y` is the dependent variable and `x` is the explanatory variable. This can be read as "*y* depends on *x*." 

Notice we don't need `counties$` before the variable names, because we are using the `data` argument to tell R where the data is coming from. We are going to save the results as the object *My.first.model* and then use the `summary()` function to present the output.


```{r first, exercise=TRUE}
My.first.model <- lm(dem2p_percent ~ wage_growth, data = counties)
summary(My.first.model)
```




 
 
```{r letter-a1, echo=FALSE}
question("What is estimated intercept in this regression?",
  answer("31.35213", correct=TRUE),
  answer("7.431", message="7.431 is the t-statistic for the slope for wage_growth"),
    answer("0.45582", message="0.45582 is the estimated slope for wage_growth"),
  allow_retry = TRUE
  )
```
  
```{r letter-a2, echo=FALSE}
question("What is estimated slope coefficient for wage_growth?",
  answer("31.35213", message="31.35213 is the intercept"),
  answer("0.39069", message="0.39069 is the standard error for the estimated intercept"),
    answer("0.45582", correct=TRUE),
  allow_retry = TRUE
  )
```


### Interpret the Estimated Coefficients 

Now that you've found the estimated coefficients let's determine what the model tells us about the relationship between **wage_growth** and **dem2p_percent**.

<span style="color:blue">The intercept ($\hat{\alpha})$</span> (conveniently labeled as such) is estimated to be 31.3521.  Recall that the intercept is the expected value of the dependent variable when the explanatory variable has a value of zero. <span style="color:green">*The intercept tells us that if a county's wage growth was flat (zero), we expect the county to cast 31.3521% of their vote for Hillary Clinton.*</span>  Note that because zero is a value of the independent variable that occurs in the data, its substantive interpretation is meaningful in this example.
  
<span style="color:blue">The slope ($\hat{\beta}$)</span> associated with the variable **wage_growth** is 0.45582. The positive slope indicates that higher wage growth was associated with a higher percentage of the vote for Hillary Clinton. Specifically the slope tells us the amount that our dependent variable (**dem2p_percent**) changes as our independent variable (**wage_growth**) increases by one unit (one percentage point). We can interpret this as follows: <span style="color:green">*For every additional percentage point growth in wages, on average, we expect counties to cast just under half a percentage point more votes for Hillary Clinton.*</span>

### Calculating Predicted Values
  
  We can calculate the predicted vote share for Hillary Clinton in a county with the average value of wage_growth, which is 4.3 based on this regression as:
  
  $$\hat{\textbf{dem2p_percent}} = \hat{\alpha}+ \hat{\beta}\textbf{wage_growth} = 31.3521+ 0.45582\times(4.3)=35.27218.$$

 
```{r letter-a, echo=FALSE}
question("What is the vote for Hillary Clinton in a county with wage growth at the 75th percentile, which was 6.5?",
  answer("29.6283"),
  answer("36.27498", correct=TRUE, message="$\\hat{\\textbf{dem2p_percent}} = \\hat{\\alpha}+ \\hat{\\beta}\\textbf{wage_growth}\\times 6.5=33.31215+0.45582*6.5=36.27498$"),
    answer("42.5"),
  allow_retry = TRUE
  )
```
  
  
### Conduct Hypothesis Tests
  
Recall that our hypothesis test for $H_0: \beta =0$ is given by: $$t=\frac{ \hat{\beta}- \beta_0}{SE(\hat{\beta})} = \frac{ \hat{\beta}}{SE(\hat{\beta})}$$ 

Columns 2-5 (under coefficients in the summary output above) present all the pieces needed to conduct and interpret the hypothesis test: each coefficient estimate, the standard error of each coefficient estimate, the associated $t$-test value, and the p-value associated with the hypothesis test that the coefficient is 0.  (The same is true for hypothesis tests on the intercept, $\alpha$.)

We will always specify a two-tailed alternative hypothesis that the coefficient is **not** equal to zero, even if our theoretical hypothesis is directional, as this is the standard practice.

### The intercept 

Let's test the null hypothesis that the intercept is zero against the alternative that it is not zero by walking through the five steps for hypothesis testing.

**Step 1: State the null hypothesis**. $H:_0\alpha=0$

**Step 2: State the alternative hypothesis**. $H:_A \alpha\ne0$

**Step 3: Compute the test statistic**. R calculates the t-statistic for the estimated coefficients and reports it in the summary output.

```{r letter-heffalump, echo=FALSE}
question("Look at the output above. What is the t-statistic for the intercept?",
  answer("80.111", message="Look closer!"),
  answer("80.249", correct=TRUE),
    answer("7.431", message="7.431 is the t-statistic for the estimate of the slope for wage_growth"),
  allow_retry = TRUE
  )
```

**Step 4: Determine the p-value**. The p-value is also reported in the output.

```{r letter-heffalump2, echo=FALSE}
question("Look at the output above. What is the p-value for the intercept?",
  answer("1.39e-13 ", message="This is the p-value for the estimated slope for wage_growth"),
  answer("< 2e-16", correct=TRUE, message = "Note that we **never** report a p-value this way. Instead we say p<0.000"),
    answer("7.431", message="7.431 is the t-statistic for the estimate of the slope for wage_growth"),
  allow_retry = TRUE
  )
```

**Step 5: Draw a conclusion**. The intercept value has a large $t$-statistic and a very small p-value. We can thus reject the null hypothesis that the intercept is zero. Specifically, since p<0.05, we can be 95% confident the intercept is not zero. In fact, it is <0.00 so we are at least 99% confident the intercept is not zero.  Similarly, the t-statistic is greater than the critical value of 1.96. This information also tells us that we can reject the null hypothesis.

### The slope 

Let's walk through the hypothesis testing steps to test whether the slope coefficient is different from zero.

**Step 1: State the null hypothesis**. 1. $H:_0\beta_{WG}=0$. 

**Step 2: State the alternative hypothesis**. $H:_A \beta_{WG}\ne0$

**Step 3: Compute the test statistic**.  The t-statistic reported in the table is 7.431.  Make sure you can find this in the output above.

**Step 4: Determine the p-value**. The p-value reported in the output is 1.39e-13. Again, make sure you can find this information in the output.

**Step 5: Draw a conclusion**.  The slope estimate has a large $t$-statistic and a very small p-value. Here, too, we can reject the null hypothesis that the slope is zero. The evidence tells us that there is a statistically significant relationship between **wage_growth** and vote for Hillary Clinton.

### Assess Model Fit

Let's begin by finding the value of 
<span style="color:blue">$R^2$</span> and <span style="color:blue">the residual standard error</span>.

```{r letter-heffalump4, echo=FALSE}
question("Look at the output above. What is the value of $R^2$?",
  answer("0.01741", message="0.01741 is the adjusted $R^2$"),
  answer("0.01746", correct=TRUE),
    answer("0.1746", message="Look more closely at the output!"),
  allow_retry = TRUE
  )
```


```{r letter-heffalump5, echo=FALSE}
question("Look at the output above. True or False, the value of the residual standard deviation is 15.99?",
  answer("TRUE", correct=TRUE),
  answer("FALSE", message="Double-check the output"),
  allow_retry = TRUE
  )
```


### $R^2$


<span style="color:blue">$R^2$</span>. The Multiple R-squared reported in the output tells us the proportion of the variance in the vote for Hillary Clinton that can be explained by all the variables in the model, which here is just **wage_growth**. The proportion of the variance explained by this model is 0.01746. Normally we present this as a percentage so that we say "1.746% of the variation in the percent of the two-party vote won by Hillary Clinton was explained by county wage growth." Not very much! (We'll talk about the Adjusted R-squared next week.)

### Residual standard error

<span style="color:blue">Residual standard error.</span> The residual standard error is the standard deviation of the residuals. The residual standard error tells us the typical difference between the observed values of the dependent variable and the values predicted by the model. In this example, the residual standard error is about 15.99 percentage points. Thus are preditions are off, on average, but about 16 points. Not so hot!


## Example 2: Vote for Hillary Clinton and Percent Black

The Democratic Party has consistently garnered more support from black voters than the Republican Party, considerably more. This leads to the following hypothesis:

 <span style="color:Chocolate">In a comparison of counties, those with higher percentages of blacks will cast a higher percentage of the two-party vote share for Hillary Clinton than those counties with lower percentages of blacks</span>
 


### Estimate the regression

 Still using the data frame **counties**, let's estimate a simple regression to test this hypothesis. Model Hillary Clinton's vote (**dem2p_percent**) as a function of the percent of a county that is Black (**black_percent**).

Edit the code below, replacing XXX with the appropriate code, and run it.

```{r second, exercise=TRUE}
My.second.model <- lm(XXX, data = XXX)
summary(My.second.model)
```

```{r second-hint-1}
You need to specify the formula for the regression inside lm().
Remember that you specify the dependent variable first, followed by 
the tilde and the independent variable.
```

```{r second-solution}
My.second.model <- lm(dem2p_percent ~ black_percent, data = counties)
summary(My.second.model)
```

```{r second-check}
grade_code()
```


### Interpret the coefficients

Look at the output above and answer the following question.

```{r letter-b, echo=FALSE}
question("Which of the following statements are true?",
  answer("For every one percentage point increase in the percent of the vote won by Hillary Clinton, there were 0.52584 percentage points more black residents in the county", message="The slope coefficient tells us the expected increase in the dependent variable with each unit increase in the independent variable"),
  answer("When there were no blacks living in a county, on average 28.14355 percent of the vote was won by Hillary Clinton", correct=TRUE),
  answer("For every one percentage point increase in the percent of black residents in a county, there was an average increase of 0.52584 percentage points in the vote won by Hillary Clinton",  correct=TRUE, message="The intercept tells us the average vote share for Hillary Clinton when the independent variable equals zero, 28.14355. When the independent variable changes by one unit, the dependent variable increases by the slope, so a one-point increase in the percent black leads to an average increase in Hillary Clinton's share of the vote of about half a point."),
  allow_retry = TRUE,
  try_again = "Hint: There is more than one correct answer"
  )
```

### Conduct Hypothesis Tests

For this example, we will test the null hypothesis that the slope is zero in the regression above. 

**Step 1: State the null hypothesis** and **Step 2: State the alternative hypothesis**


```{r letter-c, echo=FALSE}
question("Which of the following statements are true?",
  answer("To test the hypothesis that the percent of blacks in a county had no effect on vote for Hillary Clinton, the null and alternative hypothesis are given by $H_0: \\beta_{B}=0$; $H_A: \\beta_{B}\\ne0$", correct=TRUE),
  answer("To test the hypothesis that the percent of blacks in a county had no effect on vote for Hillary Clinton, the null and alternative hypothesis are given by $H_0: \\alpha=0$; $H_A: \\alpha\\ne0$", message="$H_0: \\alpha=0$; $H_A: \\alpha\\ne0$ refer to the intercept and not the slope coefficient"),
  allow_retry = TRUE
  )
```


**Step 3: Compute the test statistic** and **Step 4: Determine the p-value**.  

```{r letter-d, echo=FALSE}
question("Find the t-statistic and p-value for the slope in the output above",
  answer("The t-statistic is 30.26 and the p-value is <2e-16", correct=TRUE),
  answer("The t-statistic is 91.56 and the p-value is <2e-16", message="This is the t-statistic and p-value on the intercept"),
  allow_retry = TRUE,
  try_again = "Try again"
  )
```

**Step 5: Draw a conclusion**.

```{r letter-e, echo=FALSE}
question("Which of the following statements are true?",
  answer("Because the p-value is less than 0.05, we can reject the null hypothesis with 95% confidence and conclude the percent of black residents in a county is significantly related to the percent of the vote received by Hillary Clinton", correct=TRUE),
  answer("Because the p-value is less than 0.05, we cannot reject the null hypothesis with 95% confidence and conclude the percent of black residents in a county is significantly related to the percent of the vote received by Hillary Clinton",  message="Remember if p is low the null must go!"),
  answer("Because the absolute value of the t-statistic is greater than 1.96, we can reject the null hypothesis", correct=TRUE),
  answer("Because the confidence interval does not include the null value, we can reject the null hypothesis", correct=TRUE),
  allow_retry = TRUE,
  try_again = "Hint: Make sure to select all true statements."
  )
```

### Assess model fit

Find the $R^2$ and residual standard error in the output above and answer the following question.

```{r letter-f, echo=FALSE}
question("Which of the following statements are true?",
  answer("$R^2=0.2276$ implies that for every percentage point increase in the percent of black residents in a county on average Hillary Clinton's vote increased by 0.2276 percentage points", message="The expected increase in the vote for Hillary Clinton with each percentage point increase in the percent of black residents is given by the slope, not  $R^2$ interpretation"),
  answer("$R^2=0.2276$ implies that the percent of a county's residents that are black accounts for less than five percent of the variation in Hillary Clinton's vote",  message="You need to multiply $R^2$ by 100 to get the percentage of the variation explained by the model"),
  answer("$R^2=0.2276$ implies that the percent of a county's residents that are black accounts for about 23 percent of the variation in Hillary Clinton's vote", correct=TRUE),
  answer("The residual standard error implies that for a typical county our error in predicting Hillary Clinton's vote share based on the model is 14.2 percentage points", correct=TRUE, message="We multiple the value of $R^2$ by 100 to get the percent of the variation in the dependent variable that is explained by the model. The residual standard error tells the average amount of error in our predictions."),
  allow_retry = TRUE,
  try_again = "Hint: Make sure to select all true statements."
  )
```

## Example 3: Vote for Hillary Clinton and White Majority Counties

Still continuing to work with the data frame **counties**, assume we want to know the effect that being white majority has on a county's vote for Hillary Clinton.  We begin the following hypothesis:

<span style="color:Chocolate">In a comparison of counties, those with a majority white population will cast a lower percentage of the two-party vote share for Hillary Clinton than those counties without a majority white population.</span>


### Estimate the regression

Enter and run the code to specify a regression model using the variables **dem2p_percent** and **White**. **White** is coded 0 if the county is not majority white and 1 if the county is majority white. Thus, our independent variable is a dichotomous/binary/two-category variable for this example. 

Name your model **My.third.model** and summarize the output.

```{r third, exercise=TRUE}

```

```{r third-hint-1}
Start by specifying My.third.model and setting it 
equal to the results of the lm() function
```

```{r third-hint-2}
You need to specify the formula for the regression inside lm().
Remember that you specify the dependent variable first, followed by 
the tilde and the independent variable. Because White is coded 0, 1,
we should wrap it in the factor() function.
Don't forget to specify the data argument.
```

```{r third-hint-3}
The last step is to use the summary() function, passing it My.third.model
```

```{r third-solution}
My.third.model <- lm(dem2p_percent ~ factor(White), data = counties)
summary(My.third.model)
```

```{r third-check}
grade_code()
```

### Interpret the coefficients

Remember that the slope coefficient on a binary categorical variable is interpreted differently than that on an interval variable. 

```{r letter-g, echo=FALSE}
question("Which of the following statements are true?",
  answer("On average majority white counties cast 32.001 percentage points fewer votes for Hillary Clinton than non-majority white counties", correct=TRUE, message = "The slope, $\\beta_{W}=-32.001$ gives the difference between the percentage of votes cast for Hillary Clinton by majority white counties compared to non-white majority counties. "),
  answer("Majority white counties cast an average of about 63.802% of their votes for Hillary Clinton", message="To calculate the average vote cast for majority white counties you need to add the intercept and slope"),
  answer("On average majority-white counties cast 31.801 percent of their votes for Hillary Clinton", correct=TRUE, message="Majority white counties cast on average $\\alpha+ \\beta_{W}=63.802-32.001=31.801$ percent of their votes for Hillary Clinton. "),
  answer("For every one percentage point increase in the percent of white  residents in a county, there was an average decrease of about 32 percentage points in the vote won by Hillary Clinton",  message="White is a dichotomous variable so we cannot interpret it in terms of a one percentage point increase"),
  answer("Non-majority white counties cast an average of 63.802% of their votes for Hillary Clinton", correct=TRUE, message = "The percent of votes cast for Hillary Clinton in non-majority white counties is equal to $\\alpha$, the intercept: 63.802%. "),
  allow_retry = TRUE,
  try_again = "Hint: Be sure to select all correct answers"
  )
```

### Conduct hypothesis tests

For this example, we will focus our attention on the estimate of the slope for **White**.


**Step 1: Specify the null hypothesis** and **Step 2: Specify the alternative hypothesis**:  To test the hypothesis that majority white counties cast no more or no fewer votes for Hillary Clinton than non-majority white counties, the null and alternative hypothesis are given by $H_0: \beta_{W}=0$; $H_A: \beta_{W}\ne0$.

**Step 3: Compute the test statistic** and **Step 4: Determine the p-value**. Find the t-statistic and p-value for the slope in the output above.

**Step 5: Draw a conclusion**.

```{r letter-h, echo=FALSE}
question("Which of the following statements are true?",
  answer("Because the p-value is less than 0.05, we can reject the null hypothesis with 95% confidence and conclude the percent of white residents in a county is significantly related to the percent of the vote received by Hillary Clinton", correct=TRUE),
  answer("Because the p-value is less than 0.05, we cannot reject the null hypothesis with 95% confidence and conclude the percent of white residents in a county is significantly related to the percent of the vote received by Hillary Clinton",  message="Remember if p is low the null must go!"),
  answer("Because the absolute value of the t-statistic is greater than 1.96, we can reject the null hypothesis", correct=TRUE),
  answer("Because the confidence interval does not include the null value, we can reject the null hypothesis", correct=TRUE),
  answer("There is less than a five percent probability the null hypothesis is true", correct=TRUE, message="If the p-value is less than 0.05, the t-statistic will be greater than 1.96 (for a two-tailed test), and the confidence interval will not include the value under the null (zero). Each of these facts means we can reject the null hypothesis. The p-value gives the probability we observe a coefficient this far from the hypothesized value if in fact the null is true. Since the p-value is less than 0.01, there is less than a one percent probability the null is true. Thus we can conclude that the percentage of whites is significantly related to the vote for Hillary Clinton."),
  allow_retry = TRUE,
  try_again = "Hint: Make sure to select all true statements."
  )
```

### Assess model fit

Find the $R^2$ and residual standard deviation in the output above and answer the following question.

```{r letter-i, echo=FALSE}
question("Which of the following statements are true?",
  answer("$R^2=0.18$ implies that knowing whether a county is a majority or not majority white country explains 18% of the variation in county vote for Hillary Clinton", correct=TRUE),
  answer("The residual standard deviation implies that in more than half the counties our prediction of Hillary Clinton's vote share based on the model is off by 14.64 percentage points or less", correct=TRUE, message="We multiple the value of $R^2$ by 100 to get the percent of the variation in the dependent variable that is explained by the model. The residual standard deviation tells the average error in our predictions. We are off by quite a lot!"),
  allow_retry = TRUE,
  try_again = "Hint: Make sure to select all true statements."
  )
```



## The Takeaways

Simple linear regression is easy to conduct in R using the `lm()` function. The results of the analysis can then be examined with the `summary()` function.  The results provide all the information needed to interpret the substantive effect of the independent variable, to test hypotheses about the intercept and slope, to calculate the predicted value of the outcome variable for a particular value of the independent variable, and to assess the fit of the model.  

You will become well-practiced in conducting and interpreting the results from regression analysis in future tutorials.  For now, remember:

+ The <span style="color:blue">intercept</span> gives the value of the dependent variable, $Y$, when the independent variable $X=0$. The <span style="color:blue">slope</span> is the change in $Y$ when $X$ changes by 1 unit.
+ Anytime the value of the t-statistic for an estimated coefficient is greater than 1.96 in absolute value, the associated p-value will be less than 0.05, the confidence interval around the coefficient estimate will not include zero and we can reject the null hypothesis that the coefficient is zero with 95% confidence. Conversely, if the t-statistic is smaller than 1.96, the p-value will be greater than 0.05, the confidence interval will include zero, and we cannot reject the null hypothesis. If we cannot reject the null hypothesis on the slope coefficient, we conclude that that independent variable does not have significant explanatory value, i.e., it does not contribute to our explanation of the outcome variable.
+ <span style="color:blue">$R^2$</span> gives the proportion of the variation in $Y$ explained by the independent variables in the model. Bigger is better.
+ The <span style="color:blue">residual standard error</span> gives the standard deviation of the residuals. Because the empirical rule tells us 68% of the data will fall within one standard deviation of the mean, the residual standard error can be interpreted as telling us that more than half of the errors in our model are within X -- the value of the residual standard error -- from the regression line (the mean of the residuals is always zero). Smaller is better as it means the data is clustered closer to the regression line.